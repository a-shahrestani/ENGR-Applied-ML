{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# The required libraries are imported here\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import skimage.exposure as exposure\n",
    "from scipy import ndimage\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gargo\\AppData\\Local\\Temp\\ipykernel_14648\\4061354742.py:312: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data), new_classes, classes_dict\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PIL import ImageOps\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "# This cell contains the functions defined to read the images from the given directories,\n",
    "# separate them into classes, and preprocess them so they can be used by thr model.\n",
    "\n",
    "def image_cropper(img: np.array, height_percentage: int = 40, width_percentage: int = 40) -> np.array:\n",
    "    \"\"\"\n",
    "    the image is cropped from both sides of the height and width\n",
    "    :param img: the images as an np.array\n",
    "    :param width_percentage: the percentage of the pixels from the width of the image we would like to crop\n",
    "    :param height_percentage: the percentage of the pixels from the height of the image we would like to crop\n",
    "    :return: cropped image as np.array\n",
    "    \"\"\"\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    cropped_height_amount = height // 100 * height_percentage\n",
    "    cropped_width_amount = height // 100 * width_percentage\n",
    "    img = img[cropped_height_amount // 2:height - cropped_height_amount // 2,\n",
    "          cropped_width_amount // 2:width - cropped_width_amount // 2]\n",
    "    return img\n",
    "\n",
    "\n",
    "def dynamic_image_cropper(img: np.array, region_of_interest=500) -> np.array:\n",
    "    # print(img)\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    center = [height // 2, width // 2]\n",
    "    right_top_corner = [0, width - 1]\n",
    "    left_top_corner = [0, 0]\n",
    "    right_bottom_corner = [height - 1, width - 1]\n",
    "    left_bottom_corner = [height - 1, 0]\n",
    "    left_bottom_corner_mean = np.mean(img[left_bottom_corner[0] - region_of_interest:left_bottom_corner[0],\n",
    "                                      left_bottom_corner[1]:left_bottom_corner[1] + region_of_interest])\n",
    "    left_top_corner_mean = np.mean(img[left_top_corner[0]: region_of_interest + left_bottom_corner[0],\n",
    "                                   left_bottom_corner[1]:left_bottom_corner[1] + region_of_interest])\n",
    "    right_top_corner_mean = np.mean(img[right_top_corner[0]:right_top_corner[0] + region_of_interest,\n",
    "                                    right_top_corner[1] - region_of_interest: right_top_corner[1]])\n",
    "    right_bottom_corner_mean = np.mean(img[right_bottom_corner[0] - region_of_interest:right_bottom_corner[0],\n",
    "                                       right_bottom_corner[1] - region_of_interest:right_bottom_corner[1]])\n",
    "    center_mean = np.mean(img[center[0] - region_of_interest // 2:center[0] + region_of_interest // 2,\n",
    "                          center[1] - region_of_interest // 2:center[1] + region_of_interest // 2])\n",
    "    # print(np.array(\n",
    "    #     [center_mean, left_top_corner_mean, left_bottom_corner_mean, right_top_corner_mean, right_bottom_corner_mean]))\n",
    "\n",
    "    min_mean = np.argmin(np.array(\n",
    "        [center_mean, left_top_corner_mean, left_bottom_corner_mean, right_top_corner_mean, right_bottom_corner_mean]))\n",
    "    # print(min_mean)\n",
    "    if min_mean == 0:\n",
    "        return img[center[0] - region_of_interest // 2:center[0] + region_of_interest // 2,\n",
    "               center[1] - region_of_interest // 2:center[1] + region_of_interest // 2]\n",
    "    elif min_mean == 1:\n",
    "        return img[left_top_corner[0]: region_of_interest + left_bottom_corner[0],\n",
    "               left_bottom_corner[1]:left_bottom_corner[1] + region_of_interest]\n",
    "    elif min_mean == 2:\n",
    "        return img[left_bottom_corner[0] - region_of_interest:left_bottom_corner[0],\n",
    "               left_bottom_corner[1]:left_bottom_corner[1] + region_of_interest]\n",
    "    elif min_mean == 3:\n",
    "        return img[right_top_corner[0]:right_top_corner[0] + region_of_interest,\n",
    "               right_top_corner[1] - region_of_interest: right_top_corner[1]]\n",
    "    elif min_mean == 4:\n",
    "        return img[right_bottom_corner[0] - region_of_interest:right_bottom_corner[0],\n",
    "               right_bottom_corner[1] - region_of_interest:right_bottom_corner[1]]\n",
    "\n",
    "def dynamic_image_cropper2(img):\n",
    "    # print(img)\n",
    "    # print(img.shape)\n",
    "    img = np.uint8(img)\n",
    "    gray_negative = abs(255-img)\n",
    "    img = gray_negative\n",
    "    blur = cv2.GaussianBlur(img, (5,5), cv2.BORDER_DEFAULT)\n",
    "    # img = img + (img-blur)\n",
    "    edges= cv2.Canny(img, 100,200)\n",
    "    contours, hierarchy= cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)\n",
    "\n",
    "    objects = []\n",
    "    for (i,c) in enumerate(sorted_contours):\n",
    "        x,y,w,h= cv2.boundingRect(c)\n",
    "        new = img[y- 10:y+h + 10, x- 10:x+w + 10]\n",
    "        new[new<110] = 0\n",
    "        objects.append(new)\n",
    "    biggest_object = np.array([[1,1],[1,1]])\n",
    "    for obj in objects:\n",
    "        if obj.shape[0] * obj.shape[1] > biggest_object.shape[0] * biggest_object.shape[1]:\n",
    "            biggest_object = obj\n",
    "    cv2.imshow(\"test\", biggest_object)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return biggest_object\n",
    "\n",
    "\n",
    "\n",
    "def image_scaler(img, new_height=20, new_width=20):\n",
    "    \"\"\"\n",
    "    :param img: the images as an np.array\n",
    "    :param new_height: the new height of the scaled image\n",
    "    :param new_width: the new width of the scaled image\n",
    "    :return: scaled image as np.array\n",
    "    \"\"\"\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((new_width, new_height))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def image_standardization(img, max_value=255):\n",
    "    \"\"\"\n",
    "    changes the values of the image pixels to be between 0 and max_value\n",
    "    :param max_value: max_value of the new pixels\n",
    "    :param img: the images as an np.array\n",
    "    :return: standardized image\n",
    "    \"\"\"\n",
    "    # print(np.min(img), np.max(img))\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img)) * max_value\n",
    "    # img = (img // 16) * 16\n",
    "    return img\n",
    "\n",
    "\n",
    "def separate_classes(img_files, name_separation_chars=3, test_flag=False, classes_dict=None):\n",
    "    \"\"\"\n",
    "    separates the images into classes based on their file names\n",
    "    :param img_files: list of image file names\n",
    "    :param name_separation_chars: number of characters in the name that should get used for separation\n",
    "    :return: a list of classes for image names, a dict containing the name and the corresponding class number of images\n",
    "    \"\"\"\n",
    "    names = list(set(img_name[:name_separation_chars] for img_name in img_files))\n",
    "    if not test_flag:\n",
    "        classes_dict = dict(enumerate(names))\n",
    "        classes_dict = {v: k for k, v in classes_dict.items()}\n",
    "    classes = []\n",
    "    for img_name in img_files:\n",
    "        classes.append(classes_dict[img_name[:name_separation_chars]])\n",
    "    return classes, classes_dict\n",
    "\n",
    "\n",
    "def get_files_list(data_dir, name_separation_chars=3, test_flag=False, classes_dict=None):\n",
    "    \"\"\"\n",
    "    gets the list of image names from the directory\n",
    "    :param data_dir: path to the image files\n",
    "    :return: list of image names, their classes and the dict for classes\n",
    "    \"\"\"\n",
    "    data = os.listdir(data_dir)\n",
    "    ### print(data, len(data))\n",
    "    classes, classes_dict = separate_classes(data, name_separation_chars=name_separation_chars, test_flag=test_flag,\n",
    "                                             classes_dict=classes_dict)\n",
    "    return data, classes, classes_dict\n",
    "\n",
    "\n",
    "def image_reader(img_dir):\n",
    "    \"\"\"\n",
    "    reads image in grayscale\n",
    "    :return: img as np.array\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_dir)\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "\n",
    "def calculate_image_edges(img, total_extracted_features, threshold=100, peak_threshold=0.3, cutoff_percentage=20):\n",
    "    img_edges = img.filter(ImageFilter.FIND_EDGES)\n",
    "    # display(img_edges)\n",
    "    edge_array = np.array(img_edges)\n",
    "    edge_array = edge_array[4:edge_array.shape[0] - 4, 4:edge_array.shape[1] - 4]\n",
    "    edge_array[edge_array < threshold] = 0\n",
    "    # print(edge_array)\n",
    "    edges_v = np.sum(edge_array, axis=0).astype(float)\n",
    "    # print(edges_v.shape)\n",
    "    edges_h = np.sum(edge_array, axis=1).astype(float)\n",
    "    # print(edges_h.shape)\n",
    "    # edges_sum = np.hstack(edges_v,edges_h)\n",
    "    # print(edges_sum.shape)\n",
    "    # print(\"edges_h1\",edges_h)\n",
    "    # M = 4\n",
    "    # edges_v_copy = edges_v.copy()\n",
    "    # for i in range(M // 2, len(edges_v) - M // 2):\n",
    "    #     edges_v[i] = edges_v[i] - np.mean(edges_v_copy[i - M // 2:i + M // 2])\n",
    "    # edges_v[:M // 2] = 0\n",
    "    # edges_v[-M // 2:] = 0\n",
    "    # edges_h_copy = edges_h.copy()\n",
    "    # # print(\"edges_h1\", edges_h_copy)\n",
    "    # for j in range(M // 2, len(edges_h) - M // 2):\n",
    "    #     # print(np.mean(edges_h_copy[j - M // 2:j + M // 2]))\n",
    "    #     # print(edges_h[j])\n",
    "    #     edges_h[j] = edges_h[j] - np.mean(edges_h_copy[j - M // 2:j + M // 2])\n",
    "    # edges_h[:M // 2] = 0\n",
    "    # edges_h[-M // 2:] = 0\n",
    "    # cutoff = edge_array.shape[0] * cutoff_percentage // 100\n",
    "    # edges_h = edges_h[cutoff:-cutoff]\n",
    "    # edges_v = edges_v[cutoff:-cutoff]\n",
    "    # print(\"edges_h2\", edges_v)\n",
    "    # peak_v = np.max(np.abs(edges_v))\n",
    "    # peak_h = np.max(np.abs(edges_h))\n",
    "    # # low_v = np.min(edges_v)\n",
    "    # edges_v[np.abs(edges_v) < peak_v * peak_threshold] = 0\n",
    "    # edges_h[np.abs(edges_h) < peak_h * peak_threshold] =\n",
    "\n",
    "    edges_v_indexes = np.sort(edges_h.argsort()[-total_extracted_features // 2:][::-1])\n",
    "\n",
    "    edges_v_extracted = edges_v[edges_v_indexes]\n",
    "    # print(edges_v_extracted)\n",
    "    edges_h_indexes = np.sort(edges_h.argsort()[-total_extracted_features // 2:][::-1])\n",
    "    edges_h_extracted = edges_h[edges_h_indexes]\n",
    "\n",
    "    # edges_v_extracted = np.array(edges_v_extracted)\n",
    "    # edges_h_extracted = np.array(edges_h_extracted)\n",
    "    # # # print(noise_v,noise_h)\n",
    "    # sd_v = np.sqrt(np.var(noise_v))\n",
    "    # sd_h = np.sqrt(np.var(noise_h))\n",
    "    # # # print(sd_h,sd_v)\n",
    "    # # # sd_h, sd_v = peak_h,peak_v\n",
    "    # x = np.array([edges_v / sd_v, edges_h / sd_h]).reshape(1, -1)\n",
    "    # scaler = MinMaxScaler()\n",
    "    # x = np.array([scaler.fit_transform(edges_v_extracted.reshape(-1,1)), scaler.fit_transform(edges_h_extracted.reshape(-1,1))]).reshape(1, -1)\n",
    "    # print(len(edges_v_extracted))\n",
    "    # print(edges_v_extracted)\n",
    "    x = np.array([edges_v_extracted, edges_h_extracted]).reshape(-1, 1)\n",
    "    # print(x.shape)\n",
    "    return x\n",
    "\n",
    "def calculate_image_edges2(img, total_extracted_features, threshold=100, peak_threshold=0.3, cutoff_percentage=20):\n",
    "    img = np.array(img)\n",
    "    # blur\n",
    "    # img = img + (img - cv2.GaussianBlur(img, (5,5), cv2.BORDER_DEFAULT))\n",
    "    blur = cv2.GaussianBlur(img, (5,5), cv2.BORDER_DEFAULT)\n",
    "    edge_array = cv2.Canny(image=blur, threshold1=100, threshold2=200, apertureSize= 3)\n",
    "    # cv2.imshow(\"test\", edge_array)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    edges_v = np.sum(edge_array, axis=0).astype(float)\n",
    "    edges_h = np.sum(edge_array, axis=1).astype(float)\n",
    "    # print(edges_h.shape)\n",
    "    # print(edges_v.shape)\n",
    "    edges_v_indexes = np.sort(edges_v.argsort()[-total_extracted_features // 2:][::-1])\n",
    "    # print(edges_v_indexes)\n",
    "    edges_v_extracted = edges_v[edges_v_indexes]\n",
    "\n",
    "    edges_h_indexes = np.sort(edges_h.argsort()[-total_extracted_features // 2:][::-1])\n",
    "    edges_h_extracted = edges_h[edges_h_indexes]\n",
    "    # x = np.array([edges_v_extracted, edges_h_extracted]).reshape(-1, 1)\n",
    "    x = np.array([edges_v_extracted, edges_h_extracted]).reshape(-1, 1)\n",
    "    return x\n",
    "    # print(sobelx)\n",
    "    # cv2.imshow(\"test\", sobelx)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # print('--------')\n",
    "    # print(sobely)\n",
    "    # cv2.imshow(\"test\", sobely)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # print('--------')\n",
    "    # print(sobelxy)\n",
    "    # cv2.imshow(\"test\", sobelxy)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # print('--------')\n",
    "    # print(edges)\n",
    "\n",
    "def calculate_image_edges3(img, total_extracted_features, threshold=100, peak_threshold=0.3, cutoff_percentage=20):\n",
    "    vertical = np.sum(img, axis = 0)\n",
    "    horizontal = np.sum(img, axis = 1)\n",
    "    # vertical[vertical<np.max(vertical) * 0.05] = 0\n",
    "    # horizontal[horizontal<np.max(horizontal) * 0.05] = 0\n",
    "    vertical[vertical == 0] = sorted(set(vertical))[1]\n",
    "    horizontal[horizontal == 0] = sorted(set(horizontal))[1]\n",
    "    edges_v_indexes = np.sort(vertical.argsort()[-total_extracted_features // 2:][::-1])\n",
    "    # print(edges_v_indexes)\n",
    "    edges_v_extracted = vertical[edges_v_indexes]\n",
    "    edges_h_indexes = np.sort(horizontal.argsort()[-total_extracted_features // 2:][::-1])\n",
    "    # print(edges_v_indexes)\n",
    "    edges_h_extracted = horizontal[edges_h_indexes]\n",
    "    x = np.array([edges_v_extracted, edges_h_extracted])\n",
    "    # print(x)\n",
    "    # print((x+1).shape)\n",
    "    # x = np.log2(x + 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def get_data(path_to_training_data,\n",
    "             class_name_chars=3,\n",
    "             test_flag=False,\n",
    "             classes_dict=None,\n",
    "             augment_data=True,\n",
    "             augments=[90, 45]\n",
    "             ):\n",
    "    data = []\n",
    "    image_names, classes, classes_dict = get_files_list(path_to_training_data, class_name_chars, test_flag=test_flag,\n",
    "                                                        classes_dict=classes_dict)\n",
    "    new_classes = []\n",
    "    for i, name in enumerate(image_names):\n",
    "        img = image_reader(str(Path(path_to_training_data) / name))\n",
    "        data.append(np.array(img))\n",
    "        new_classes.append(classes[i])\n",
    "        if augment_data:\n",
    "            for value in augments:\n",
    "                rotated = ndimage.rotate(img, value)\n",
    "                rotated = np.array(rotated)\n",
    "                rotated[rotated == 0] = np.mean(np.array(img)[0:20, 0:20])\n",
    "                data.append(rotated)\n",
    "                new_classes.append(classes[i])\n",
    "\n",
    "    # converting classes list to a column array\n",
    "    new_classes = np.array(new_classes).reshape(-1, 1)\n",
    "    return np.array(data), new_classes, classes_dict\n",
    "\n",
    "\n",
    "def preprocess_data(data,\n",
    "                    standardization_flag=True,\n",
    "                    standardization_max_value=255,\n",
    "                    crop_flag=True,\n",
    "                    crop_height_percentage=50,\n",
    "                    crop_width_percentage=50,\n",
    "                    scaling_flag=True,\n",
    "                    scaling_height=100,\n",
    "                    scaling_width=100,\n",
    "                    total_extracted_features=64,\n",
    "                    region_of_interest=500,\n",
    "                    scaling = True,\n",
    "                    scaler=None):\n",
    "    new_data = []\n",
    "    for img in data:\n",
    "        if standardization_flag:\n",
    "            img = image_standardization(img, standardization_max_value)\n",
    "        if scaling_flag:\n",
    "            img = image_scaler(img, scaling_height, scaling_width)\n",
    "        if crop_flag:\n",
    "            # print(img)\n",
    "            # img = np.array(img)\n",
    "            # img = dynamic_image_cropper(img, region_of_interest=region_of_interest)\n",
    "            img = dynamic_image_cropper2(img)\n",
    "            # display(Image.fromarray(img).convert('L'))\n",
    "\n",
    "\n",
    "        # img = Image.fromarray(img).convert('L')\n",
    "        img = calculate_image_edges3(img, total_extracted_features)\n",
    "        img = img.flatten()\n",
    "        # print(img)\n",
    "        new_data.append(img)\n",
    "    new_data = np.array(new_data)\n",
    "    if scaling:\n",
    "        if scaler is None:\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(new_data)\n",
    "        new_data = scaler.transform(new_data)\n",
    "    return new_data, scaler\n",
    "    # return new_data\n",
    "\n",
    "\n",
    "region_of_interest = 600\n",
    "scaling_height = 200\n",
    "scaling_width = 200\n",
    "\n",
    "\n",
    "def train_function(path_to_data,\n",
    "                   class_name_chars=3,\n",
    "                   test_flag=False,\n",
    "                   classes_dict=None,\n",
    "                   standardization_flag=True,\n",
    "                   standardization_max_value=255,\n",
    "                   crop_flag=True,\n",
    "                   crop_height_percentage=15,\n",
    "                   crop_width_percentage=15,\n",
    "                   scaling_flag=True,\n",
    "                   scaling_height=scaling_height,\n",
    "                   scaling_width=scaling_width,\n",
    "                   region_of_interest=region_of_interest,\n",
    "                   total_extracted_features=64,\n",
    "                   results=None,\n",
    "                   scaling = True,\n",
    "                   scaler=None):\n",
    "    data, y_train, classes_dict = get_data(path_to_data, class_name_chars, test_flag, classes_dict)\n",
    "    X_train, scaler = preprocess_data(data, standardization_flag=standardization_flag,\n",
    "                                      standardization_max_value=standardization_max_value, crop_flag=crop_flag,\n",
    "                                      crop_height_percentage=crop_height_percentage,\n",
    "                                      crop_width_percentage=crop_width_percentage, scaling_flag=scaling_flag,\n",
    "                                      scaling_height=scaling_height, scaling_width=scaling_width,\n",
    "                                      total_extracted_features=total_extracted_features,\n",
    "                                      region_of_interest=region_of_interest, scaling = scaling, scaler=scaler)\n",
    "    # print(X_train)\n",
    "    # train LogisticRegression model\n",
    "    model = LogisticRegression(max_iter=5000000)\n",
    "    # print(X_train)\n",
    "    # print(X_train.shape)\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "\n",
    "    print(f'\\nX_train.shape = {X_train.shape}, y_train.shape = {len(y_train)}')\n",
    "    y_pred = model.predict(X_train)\n",
    "\n",
    "    # Reporting the stats from the model\n",
    "    print(f'\\nConfusion Matrix = \\n{confusion_matrix(y_train, y_pred)}')\n",
    "    print(f'\\nAccuracy Score = {accuracy_score(y_train, y_pred)}')\n",
    "    print(f'Model Coefficient Shape = {model.coef_.shape}')\n",
    "    if results is not None:\n",
    "        results.append(accuracy_score(y_train, y_pred))\n",
    "    return model, classes_dict, results, scaler\n",
    "\n",
    "\n",
    "model, classes_dict, results, scaler = train_function('../../data/Lego_dataset_2/training/')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gargo\\AppData\\Local\\Temp\\ipykernel_14648\\3035317372.py:312: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data), new_classes, classes_dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_test.shape = (81, 64), y_test.shape = 81\n",
      "{'squ': 0, 'cir': 1, 'rec': 2}\n",
      "[ 3  8  9 16 18 28 53 55 62 63 64 66 69 73 74 75 76 81]\n",
      "\n",
      "Confusion Matrix = \n",
      "[[16  4  7]\n",
      " [ 4 22  1]\n",
      " [ 2  0 25]]\n",
      "\n",
      "Accuracy Score = 0.7777777777777778\n",
      "Model Coefficient Shape = (3, 64)\n"
     ]
    }
   ],
   "source": [
    "# The test function uses the get_data function as a base to read all the images from the given directory, get their classes based on the classes_dict from the training function, prepare the dataset, and then predict the classes of the images.\n",
    "\n",
    "def test_function(path_to_data,\n",
    "                  model,\n",
    "                  class_name_chars=3,\n",
    "                  test_flag=False,\n",
    "                  classes_dict=None,\n",
    "                  standardization_flag=True,\n",
    "                  standardization_max_value=255,\n",
    "                  crop_flag=True,\n",
    "                  crop_height_percentage=10,\n",
    "                  crop_width_percentage=10,\n",
    "                  scaling_flag=True,\n",
    "                  scaling_height=scaling_height,\n",
    "                  scaling_width=scaling_width,\n",
    "                  region_of_interest=region_of_interest,\n",
    "                  total_extracted_features=64,\n",
    "                  results=None,\n",
    "                  scaling = True,\n",
    "                  scaler = None):\n",
    "    data, y_test, classes_dict = get_data(path_to_data, class_name_chars, test_flag, classes_dict, augment_data= False)\n",
    "    X_test, scaler = preprocess_data(data, standardization_flag=standardization_flag,\n",
    "                             standardization_max_value=standardization_max_value, crop_flag=crop_flag,\n",
    "                             crop_height_percentage=crop_height_percentage,\n",
    "                             crop_width_percentage=crop_width_percentage, scaling_flag=scaling_flag,\n",
    "                             scaling_height=scaling_height, scaling_width=scaling_width,\n",
    "                             total_extracted_features=total_extracted_features, region_of_interest=region_of_interest, scaling = scaling, scaler = scaler)\n",
    "    # train LogisticRegression model\n",
    "    print(f'\\nX_test.shape = {X_test.shape}, y_test.shape = {len(y_test)}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classes_dict)\n",
    "    # print(y_pred.tolist())\n",
    "    print(np.where(y_pred != y_test.flatten())[0] + 1)\n",
    "    # Reporting the stats from the model\n",
    "    print(f'\\nConfusion Matrix = \\n{confusion_matrix(y_test, y_pred)}')\n",
    "    print(f'\\nAccuracy Score = {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Model Coefficient Shape = {model.coef_.shape}')\n",
    "    if results is not None:\n",
    "        results.append(accuracy_score(y_test, y_pred))\n",
    "    return results\n",
    "\n",
    "\n",
    "results = test_function('../../data/Lego_dataset_2/testing/', model, test_flag=True, classes_dict=classes_dict, scaler=scaler)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
